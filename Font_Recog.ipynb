{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pylab as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import ImageFilter\n",
    "import cv2\n",
    "import itertools\n",
    "import random\n",
    "import keras\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import os\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D , UpSampling2D ,Conv2DTranspose\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_image(img_path):\n",
    "    pil_im =PIL.Image.open(img_path).convert('L')\n",
    "    pil_im=pil_im.resize((105,105))\n",
    "    return pil_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Noise to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_image(pil_im):\n",
    "    img_array = np.asarray(pil_im)\n",
    "    mean = 0.0   # some constant\n",
    "    std = 5   # some constant (standard deviation)\n",
    "    noisy_img = img_array + np.random.normal(mean, std, img_array.shape)\n",
    "    noisy_img_clipped = np.clip(noisy_img, 0, 255)\n",
    "    noise_img = PIL.Image.fromarray(np.uint8(noisy_img_clipped)) # output\n",
    "    noise_img=noise_img.resize((105,105))\n",
    "    return noise_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Blur to image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_image(pil_im):\n",
    "    blur_img = pil_im.filter(ImageFilter.GaussianBlur(radius=3)) # ouput\n",
    "    #imshow(blur_img)\n",
    "    blur_img=blur_img.resize((105,105))\n",
    "    return blur_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_rotation(img):\n",
    "    \n",
    "    #img=cv2.imread(img_path,0)\n",
    "    rows, columns = img.shape\n",
    "\n",
    "    point1 = np.float32([[10, 10], [30, 10], [10, 30]])\n",
    "    point2 = np.float32([[20, 15], [40, 10], [20, 40]])\n",
    "\n",
    "    A = cv2.getAffineTransform(point1, point2)\n",
    "\n",
    "    output = cv2.warpAffine(img, A, (columns, rows))\n",
    "    affine_img = PIL.Image.fromarray(np.uint8(output)) # affine rotated output\n",
    "    #imshow(output)\n",
    "    affine_img=affine_img.resize((105,105))\n",
    "    return affine_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_fill(image):\n",
    "    laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "    laplacian = cv2.resize(laplacian, (105, 105))\n",
    "    return laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Dataset/\"\n",
    "data=[]\n",
    "labels=[]\n",
    "imagePaths = sorted(list(paths.list_images(data_path)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://fonts.google.com/specimen/Oswald\n",
    "https://fonts.google.com/specimen/Roboto\n",
    "https://fonts.google.com/specimen/Open+Sans\n",
    "https://fonts.google.com/specimen/Ubuntu\n",
    "https://fonts.google.com/specimen/PT+Serif\n",
    "https://fonts.google.com/specimen/Dancing+Script\n",
    "https://fonts.google.com/specimen/Fredoka+One\n",
    "https://fonts.google.com/specimen/Arimo\n",
    "https://fonts.google.com/specimen/Noto+Sans\n",
    "https://fonts.google.com/specimen/Patua+One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_label(label):\n",
    "    label_dict = {\n",
    "        'Oswald': 0,\n",
    "        'Roboto': 1,\n",
    "        'Open+Sans': 2,\n",
    "        'Ubuntu': 3,\n",
    "        'PT+Serif': 4,\n",
    "        'Dancing+Script': 5,\n",
    "        'Fredoka+One': 6,\n",
    "        'Arimo': 7,\n",
    "        'Noto+Sans': 8,\n",
    "        'Patua+One': 9\n",
    "    }\n",
    "    return label_dict.get(label, -1)  # Returns -1 if label is not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augument=[\"blur\",\"noise\",\"affine\",\"gradient\"]\n",
    "a=itertools.combinations(augument, 4)\n",
    "\n",
    "for i in list(a): \n",
    "    print(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    label = conv_label(label)\n",
    "    pil_img = pil_image(imagePath)  \n",
    "    \n",
    "    \n",
    "    org_img = img_to_array(pil_img)  \n",
    "    data.append(org_img)\n",
    "    labels.append(label)\n",
    "    \n",
    "    augment_functions = {\n",
    "        'noise': noise_image,  \n",
    "        'blur': blur_image,    \n",
    "        'affine': lambda img: affine_rotation(np.array(img)),  \n",
    "        'gradient': lambda img: gradient_fill(np.array(img)),  \n",
    "    }\n",
    "    \n",
    "    \n",
    "    augmentations = [\"noise\", \"blur\", \"affine\", \"gradient\"]\n",
    "    \n",
    "    for l in range(1, len(augmentations) + 1):\n",
    "        for combination in itertools.combinations(augmentations, l):\n",
    "            temp_img = pil_img\n",
    "            for aug in combination:\n",
    "                temp_img = augment_functions[aug](temp_img)\n",
    "            temp_img = img_to_array(temp_img)\n",
    "            data.append(temp_img)\n",
    "            labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"Success\")\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = to_categorical(trainY, num_classes=5)\n",
    "testY = to_categorical(testY, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True)\n",
    "K.set_image_dim_ordering('tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model=Sequential()\n",
    "\n",
    "  # Cu Layers \n",
    "  model.add(Conv2D(64, kernel_size=(48, 48), activation='relu', input_shape=(105,105,1)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Conv2D(128, kernel_size=(24, 24), activation='relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Conv2DTranspose(128, (24,24), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
    "  model.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "  model.add(Conv2DTranspose(64, (12,12), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
    "  model.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "  #Cs Layers\n",
    "  model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "  model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "  model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  model.add(Dense(4096,activation='relu'))\n",
    "\n",
    "  model.add(Dropout(0.5))\n",
    "\n",
    "  model.add(Dense(2383,activation='relu'))\n",
    "\n",
    "  model.add(Dense(5, activation='softmax'))\n",
    " \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "model= create_model()\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
    "\n",
    "filepath=\"top_model.h5\"\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY,shuffle=True,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(testX, testY),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('top_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we take a sample image and try to do the same and display the results!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "\n",
    "def rev_conv_label(label):\n",
    "    labels_dict = {\n",
    "        0: 'Oswald',\n",
    "        1: 'Roboto',\n",
    "        2: 'Open+Sans',\n",
    "        3: 'Ubuntu',\n",
    "        4: 'PT+Serif',\n",
    "        5: 'Dancing+Script',\n",
    "        6: 'Fredoka+One',\n",
    "        7: 'Arimo',\n",
    "        8: 'Noto+Sans',\n",
    "        9: 'Patua+One'\n",
    "    }\n",
    "    return labels_dict.get(label, \"Unknown Label\")\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = \"sample/sample.jpg\"\n",
    "pil_im = PIL.Image.open(img_path).convert('L')  \n",
    "pil_im = blur_image(pil_im)  \n",
    "org_img = img_to_array(pil_im)  \n",
    "org_img = np.expand_dims(org_img, axis=0)  \n",
    "org_img = org_img.astype(\"float32\") / 255.0  \n",
    "\n",
    "# Predict the label of the image\n",
    "y_pred = model.predict(org_img)\n",
    "y_pred_label = np.argmax(y_pred, axis=1)[0]  \n",
    "\n",
    "# Convert numeric label to actual font name\n",
    "label = rev_conv_label(y_pred_label)\n",
    "\n",
    "# Visualize the result\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(pil_im, interpolation='nearest', cmap=cm.gray)\n",
    "ax.text(5, 5, label, bbox={'facecolor': 'white', 'pad': 10})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
